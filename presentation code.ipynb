{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kleiner Überblick\n",
    "\n",
    "Hab mir das so gedacht, dass wir diesen Code für den Post verwenden, ist auf das Minimum reduziert. Alles was benötigt wird laden wir einfach aus dem Verzeichnis (Github?) rein damit wir ohne großen Code schnell zeigen können was wir wollen. \n",
    "\n",
    "Zweites Codefile preparation_code enthält dann den vollständigen Code mit den ganzen Berechnung etc., so wie er in unserem Standardmodell abgespeichert damit man die Berechnungen alle nachzeichnen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652\n",
    "    \n",
    "Link für Fastai, nach Erstellung des Environments aktiviert man zunächst das Environment, dann navigiert man seinen Präsiordner an\n",
    "\n",
    "conda activate fastai-cpu \n",
    "\n",
    "cd \"/Users/michaelschimpke/Documents/Präsentation/Colab Notebooks\" \n",
    "\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Einleitung\n",
    "\n",
    "Einführung Paper, Fastai, Pytorch, Transfer Learning, Tokenization, (Embedding? oder erst später?) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frage: \n",
    "\n",
    "Wie sollen wir die Import Packages handhaben? Sie meinte ja der Code im Blogpost muss durchlaufen können, aber brauchen wir wirklich die ganzen Packages? Oder geben wir das in Github nochmal extra ab mit den Packages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai==0.7.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: isoweek in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.3.3)\n",
      "Requirement already satisfied: sklearn-pandas in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.8.0)\n",
      "Requirement already satisfied: pandas-summary in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.0.6)\n",
      "Requirement already satisfied: cycler in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.10.0)\n",
      "Requirement already satisfied: pickleshare in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.7.5)\n",
      "Requirement already satisfied: ptyprocess in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.6.0)\n",
      "Requirement already satisfied: torch<0.4 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.3.1.post2)\n",
      "Requirement already satisfied: widgetsnbextension in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (3.4.2)\n",
      "Requirement already satisfied: pandas in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.24.0)\n",
      "Requirement already satisfied: numpy in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.15.4)\n",
      "Requirement already satisfied: tqdm in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (4.29.1)\n",
      "Requirement already satisfied: traitlets in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (4.3.2)\n",
      "Requirement already satisfied: wcwidth in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.1.7)\n",
      "Requirement already satisfied: webencodings in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.5.1)\n",
      "Requirement already satisfied: PyYAML in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (3.13)\n",
      "Requirement already satisfied: ipywidgets in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (7.4.2)\n",
      "Requirement already satisfied: pyparsing in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2.3.1)\n",
      "Requirement already satisfied: pytz in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2018.9)\n",
      "Requirement already satisfied: matplotlib in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2.2.3)\n",
      "Requirement already satisfied: Jinja2 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2.10)\n",
      "Requirement already satisfied: simplegeneric in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.8.1)\n",
      "Requirement already satisfied: decorator in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (4.3.0)\n",
      "Requirement already satisfied: feather-format in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.4.0)\n",
      "Requirement already satisfied: scipy in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.2.0)\n",
      "Requirement already satisfied: torchvision in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.1.9)\n",
      "Requirement already satisfied: ipykernel in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (5.1.0)\n",
      "Requirement already satisfied: bcolz in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.2.1)\n",
      "Requirement already satisfied: Pillow in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (5.4.1)\n",
      "Requirement already satisfied: MarkupSafe in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.1.0)\n",
      "Requirement already satisfied: pyzmq in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (17.1.2)\n",
      "Requirement already satisfied: html5lib in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.0.1)\n",
      "Requirement already satisfied: plotnine in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.5.1)\n",
      "Requirement already satisfied: testpath in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.4.2)\n",
      "Requirement already satisfied: Pygments in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2.3.1)\n",
      "Requirement already satisfied: tornado in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (4.5.3)\n",
      "Requirement already satisfied: entrypoints in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.3)\n",
      "Requirement already satisfied: seaborn in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2018.11.29)\n",
      "Requirement already satisfied: jsonschema in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2.6.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (2.7.5)\n",
      "Requirement already satisfied: bleach in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (3.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.2.0)\n",
      "Requirement already satisfied: graphviz in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.10.1)\n",
      "Requirement already satisfied: jedi in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.13.2)\n",
      "Requirement already satisfied: jupyter in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (1.0.0)\n",
      "Requirement already satisfied: opencv-python in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (4.0.0.21)\n",
      "Requirement already satisfied: torchtext in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (0.2.3)\n",
      "Requirement already satisfied: ipython in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from fastai==0.7.0) (7.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from sklearn-pandas->fastai==0.7.0) (0.20.2)\n",
      "Requirement already satisfied: six in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from cycler->fastai==0.7.0) (1.12.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from widgetsnbextension->fastai==0.7.0) (5.7.4)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from matplotlib->fastai==0.7.0) (1.0.1)\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from feather-format->fastai==0.7.0) (0.12.0)\n",
      "Requirement already satisfied: jupyter-client in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipykernel->fastai==0.7.0) (5.2.4)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.5.1)\n",
      "Requirement already satisfied: mizani>=0.5.2 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.5.3)\n",
      "Requirement already satisfied: descartes>=1.1.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (1.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels>=0.8.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.9.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from jedi->fastai==0.7.0) (0.3.1)\n",
      "Requirement already satisfied: jupyter-console in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (6.0.0)\n",
      "Requirement already satisfied: qtconsole in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (4.4.3)\n",
      "Requirement already satisfied: nbconvert in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (5.4.0)\n",
      "Requirement already satisfied: requests in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from torchtext->fastai==0.7.0) (2.21.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (40.6.3)\n",
      "Requirement already satisfied: backcall in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (0.1.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (0.1.0)\n",
      "Requirement already satisfied: Send2Trash in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (0.8.1)\n",
      "Requirement already satisfied: prometheus-client in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (0.5.0)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (4.4.0)\n",
      "Requirement already satisfied: palettable in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from mizani>=0.5.2->plotnine->fastai==0.7.0) (3.1.1)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==0.7.0) (0.5.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext->fastai==0.7.0) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext->fastai==0.7.0) (2.8)\n",
      "Requirement already satisfied: torchtext==0.2.3 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (0.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from torchtext==0.2.3) (4.29.1)\n",
      "Requirement already satisfied: requests in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from torchtext==0.2.3) (2.21.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext==0.2.3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext==0.2.3) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext==0.2.3) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from requests->torchtext==0.2.3) (2018.11.29)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "!pip install fastai==0.7.0\n",
    "!pip install torchtext==0.2.3\n",
    "\n",
    "import fastai\n",
    "from fastai.imports import *\n",
    "from fastai.torch_imports import *\n",
    "from fastai.core import *\n",
    "from fastai.model import fit\n",
    "from fastai.dataset import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai.text import *\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en\n",
    "import spacy\n",
    "import html\n",
    "\n",
    "import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden der fertigen Datensätze\n",
    "\n",
    "Für Präsentationscode laden wir nur die fertigen Data Frames etc. ins Modell, spart sehr viel Code ein. Die gesamte Berechnung gebenw wir im anderen Preparation_Code File ab.\n",
    "\n",
    "<b> Wichtig hier:</b> Für das Language Model laden wir die Datensätze aus dem LM Path, bei dem die Labels auf 0 gesetzt werden. Später im Classifier laden wir dann die Daten aus dem Clas Path mit den Labels.\n",
    "\n",
    "Muss mal schauen dann was wir von dem Zeug wirklich brauchen und was nicht, im Endeffekt wollen wir ja nur einen Satz in Worten und in Tokens zeigen.\n",
    "\n",
    "Die Zeile würd ich dann sogar rauslassen, ist zuviel Code.\n",
    "\n",
    "Hab zusätzlich für Stoi auch mal ein Pickle Dump erstellt, damit wir das auch zur Not schnell reinladen können. Wobei die Zeile könnten wir auch lassen ist ja nicht so arg viel und sieht so aus als könnten wir gut programmieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tokenized data\n",
    "chunksize = 5000\n",
    "dfTrn = pd.read_csv('lm/train.csv', header=None, chunksize=chunksize)\n",
    "dfVal = pd.read_csv('lm/test.csv', header=None, chunksize=chunksize)\n",
    "\n",
    "tokTrn = np.load('lm/tokTrn.npy')\n",
    "tokVal = np.load('lm/tokVal.npy')\n",
    "\n",
    "trnLm = np.load('lm/trnIds.npy')\n",
    "valLm = np.load('lm/valIds.npy')\n",
    "\n",
    "#Load presaved itos\n",
    "with open('lm/itos.pkl', 'rb') as pickle_file:\n",
    "    itos = pickle.load(pickle_file)\n",
    "\n",
    "stoi = collections.defaultdict(lambda:0, \n",
    "                               {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Schnelle Erklärung Tokenization anhand eines kurzen Beispiels\n",
    "\n",
    "Könnte dann so aussehen zb. Einmal in Worten..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', 'xbos', '@jetblue', \"'s\", 'new', 't_up', 'ceo', 'seeks', 'the', 'right', 'balance', 'to',\n",
       "       'please', 'passengers', 'and', 'wall', '...', '-', 'times', 'colonist'], dtype='<U10')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokTrn = np.load('lm/tokTrn.npy')\n",
    "np.transpose(tokTrn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... und in Zahlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    3,   26,   37,  162,    8,  642, 2150,    7,  210, 1735,    5,   89,  229,   18,  886,   57,\n",
       "         42,  252,    0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnLm = np.load('lm/trnIds.npy')\n",
    "np.transpose(trnLm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Language Model\n",
    "\n",
    "Hier geht der Teil LM los. Würde anfangen mit den Embeddings, da wir das gleich im Matching brauchen werden. Am besteb wir verknüpfen das irgendwie indem wir auch gleich das Wikipedia Pretraining Model einführen, da ich aus diesem die Embedding Matrix gleich zeigen kann.\n",
    "\n",
    "Vielleicht anfangen mit dem Wikimodell und dann hinführen auf die übernommenen trainierten Embeddings und LSTMs.\n",
    "\n",
    "Kurze Erläuterung zu Embeddings, dazu würde ich auch schnell aus Wiki die Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Bin mir noch nicht ganz schlüssig wo wir das Embedding unterbringen. Später im Numpy Part muss das eigentlich schon erklärt sein weil wir das ja im Modell auch schon trainieren um beim Matching brauchen.\n",
    "\n",
    "Da beim Matching die Embeddings übernommen würd ich das hier erklären.\n",
    "\n",
    "Zeige dann am besten die Embeddingmatrix hier, dazu kurze Erklärung wir haben 238462 Wörter im Vocabulary und jedes Wort wird durch 400 Embedding Features repräsentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.2274e-01  2.7886e-01 -3.8850e-01  ...  -1.0404e-01  1.9580e-02  1.8548e-01\n",
      " 1.4854e-05 -2.3424e-05  1.9693e-05  ...   2.1349e-05  2.1776e-05 -1.2394e-05\n",
      " 1.8070e-01  1.5874e+00 -1.1738e-01  ...  -4.5935e-02 -8.1352e-02  1.8054e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8595e-03 -6.8529e-03  1.6999e-03  ...   1.7039e-03  4.1632e-03 -1.3171e-03\n",
      "-2.3120e-03 -6.9001e-03  1.8772e-03  ...   5.0309e-04  4.6596e-03 -2.5850e-03\n",
      "-2.2463e-03 -9.1512e-03  1.3927e-03  ...   1.2296e-03  5.8085e-03 -1.8940e-03\n",
      "[torch.FloatTensor of size 238462x400]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm_wgts_wiki = torch.load('wt103/fwd_wt103.h5', map_location=lambda storage, \n",
    "                  loc: storage)\n",
    "print(lm_wgts_wiki['0.encoder.weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching\n",
    "\n",
    "Das Ding ist noch viel zu lang, da müssen wir uns überlegen ob wir das irgendwie kürzen oder über mehrere Zeilen verteilen können. Denke wir können wahrscheinlich das itoswiki und stoiwiki weglassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz, nh, nl = 400, 1150, 3\n",
    "\n",
    "with open('wt103/itos_wt103.pkl', 'rb') as pickle_file:\n",
    "    itosWiki = pickle.load(pickle_file)\n",
    "    \n",
    "stoiWiki = collections.defaultdict(lambda:-1, {v:k for k,v \n",
    "                                              in enumerate(itosWiki)})\n",
    "\n",
    "encWgts = lm_wgts_wiki['0.encoder.weight'].numpy()\n",
    "rowM = np.mean(encWgts, axis = 0)\n",
    "\n",
    "newWm = np.zeros((len(itos), em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoiWiki[w]\n",
    "    newWm[i] = encWgts[r] if r>=0 else rowM\n",
    "    \n",
    "lm_wgts_wiki['0.encoder.weight'] = np.transpose(newWm)\n",
    "lm_wgts_wiki['0.encoder_with_dropout.embed.weight'] = np.transpose(np.copy(newWm))\n",
    "lm_wgts_wiki['1.decoder.weight'] = np.transpose(np.copy(newWm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model Structure\n",
    "\n",
    "Hier können wir anfangen das Modell aufzuziehen, vielleicht erst die Parameter und dann den Learner für das Language Model. \n",
    "\n",
    "Hier würde ich das Bild vom Model Overview zum ersten Mal einfügen, passend zur allgemeinen Erklärung des Modells.\n",
    "\n",
    "Würde dann hier auch mit <b>Sandras Erläuterungen zu BPTT, Batch Size, Adam etc.</b> starten. Hier können wir das schön auseinanderziehen und dann den Learner aufziehen. Dann noch LanguageModelLoader erklären"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "bptt = 70\n",
    "bs = 64\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "t = len(np.concatenate(trnLm))\n",
    "\n",
    "trnDl = LanguageModelLoader(np.concatenate(trnLm), bs, bptt)\n",
    "valDl = LanguageModelLoader(np.concatenate(valLm), bs, bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erklärung AWD-LSTMs, Dropout, LanguageModelData Funktion\n",
    "\n",
    "Hier dann <b>AWD-LSTMs mit Dropout</b> (falls wir darauf überhaupt so viel eingehen). get_model function erklären. Danach freezing erklären"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = LanguageModelData('', 1, len(itos), trnDl, valDl, bs=bs, \n",
    "                       bptt=bptt)\n",
    "\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7\n",
    "learner = md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti = drops[0], dropout=drops[1], wdrop=drops[2],\n",
    "    dropoute = drops[3], dropouth=drops[4])\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erster Fit mit Freezing, Erklärung STLR\n",
    "\n",
    "Wir müssen meiner Meinung nach hier das Modell im Jupyter Notebook nochmal durchlaufen lassen, da wir die Modellparameter wie Loss und Accuracy sonst nicht bzw. kaum laden und zeigen können.\n",
    "\n",
    "<b>Erklärung Freezing und Slanted Triangular Learning Rates hier.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Durchführung erst ganz am Ende\n",
    "learner.model.load_state_dict(lm_wgts_wiki)\n",
    "lr=3e-3\n",
    "lrs = lr\n",
    "#learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1) \n",
    "#learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses, Accuracy 1. Epoche mit Freezing\n",
    "\n",
    "Output aus dem Model (wird natürlich noch auf wenige Schlüsselmatrizen heruntergetrimmt, um das etwas anschaulicher zu machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.encoder.weight', \n",
      "-1.5972e-01  3.2485e-01 -4.4057e-01  ...  -1.4884e-01 -4.2950e-03  1.4028e-01\n",
      " 3.7763e-02 -3.9745e-02  5.0021e-02  ...   3.9405e-02  4.0394e-02 -2.1133e-02\n",
      "-3.8825e-01 -4.0622e-01 -1.7479e-01  ...   7.0953e-02  2.7808e-01  7.5862e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.2570e-02 -1.4090e-01  1.2269e-02  ...   1.2281e-02  5.5557e-02 -4.0179e-03\n",
      "-7.3162e-01 -1.1589e+00  3.6999e-01  ...   2.3351e-01 -6.6950e-02  4.2597e-02\n",
      "-3.1653e-01 -9.5473e-01 -1.0659e-01  ...  -2.2530e-01  2.1217e-01  2.5796e-01\n",
      "[torch.FloatTensor of size 4409x400]\n",
      "), ('0.encoder_with_dropout.embed.weight', \n",
      "-1.5972e-01  3.2485e-01 -4.4057e-01  ...  -1.4884e-01 -4.2950e-03  1.4028e-01\n",
      " 3.7763e-02 -3.9745e-02  5.0021e-02  ...   3.9405e-02  4.0394e-02 -2.1133e-02\n",
      "-3.8825e-01 -4.0622e-01 -1.7479e-01  ...   7.0953e-02  2.7808e-01  7.5862e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.2570e-02 -1.4090e-01  1.2269e-02  ...   1.2281e-02  5.5557e-02 -4.0179e-03\n",
      "-7.3162e-01 -1.1589e+00  3.6999e-01  ...   2.3351e-01 -6.6950e-02  4.2597e-02\n",
      "-3.1653e-01 -9.5473e-01 -1.0659e-01  ...  -2.2530e-01  2.1217e-01  2.5796e-01\n",
      "[torch.FloatTensor of size 4409x400]\n",
      "), ('0.rnns.0.module.weight_ih_l0', \n",
      "-8.1208e-02 -8.1070e-02 -9.3667e-02  ...  -2.5917e-02 -1.4032e-01 -3.2470e-01\n",
      " 1.1539e-01  1.1424e-01  9.3782e-02  ...  -7.1087e-02  1.6688e-01 -3.8713e-02\n",
      "-5.1495e-03  1.0075e-01  2.0714e-01  ...  -8.5995e-02 -2.8766e-02 -8.9380e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 5.4658e-03  1.5655e-02  2.9896e-01  ...   6.1618e-02  1.1594e-01 -4.7367e-01\n",
      " 1.8077e-02  4.2556e-02  1.1295e-01  ...   3.5287e-01 -1.1401e-02 -1.2511e-02\n",
      "-1.6681e-02 -1.3277e-01  1.7413e-01  ...   5.4776e-02 -4.5065e-03  1.6884e-01\n",
      "[torch.FloatTensor of size 4600x400]\n",
      "), ('0.rnns.0.module.bias_ih_l0', \n",
      " 0.1503\n",
      "-0.4701\n",
      "-0.1885\n",
      "   ⋮   \n",
      "-0.5919\n",
      "-0.2172\n",
      "-0.1207\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.0.module.bias_hh_l0', \n",
      " 0.1503\n",
      "-0.4701\n",
      "-0.1885\n",
      "   ⋮   \n",
      "-0.5919\n",
      "-0.2172\n",
      "-0.1207\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.0.module.weight_hh_l0_raw', \n",
      "-1.0128e-01  1.7864e-01 -5.2847e-02  ...   7.4101e-02  3.0610e-02  2.4666e-01\n",
      " 1.7796e-01 -8.5314e-02 -2.4329e-02  ...  -1.1286e-01 -1.3102e-01 -1.4975e-01\n",
      " 6.6133e-02 -4.9570e-02  9.2117e-02  ...   1.8295e-01  5.3332e-02 -1.5251e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-3.2194e-02 -7.0374e-02  1.6533e-01  ...   2.1417e-01 -5.5782e-02  3.1469e-02\n",
      "-1.6511e-01 -2.8984e-02  1.7478e-01  ...  -4.4581e-02  5.4444e-01  6.1595e-02\n",
      " 9.0453e-02 -1.7044e-01 -5.3422e-03  ...  -5.7082e-03  2.2690e-01  3.2815e-02\n",
      "[torch.FloatTensor of size 4600x1150]\n",
      "), ('0.rnns.1.module.weight_ih_l0', \n",
      " 3.3072e-01  3.8498e-02  8.6008e-02  ...   6.8523e-02 -4.4404e-02  5.3939e-02\n",
      " 7.1970e-02  1.6074e-01  5.6188e-02  ...   2.7634e-02  6.1305e-02  1.6321e-01\n",
      "-1.5653e-01 -1.1684e-01  1.8969e-01  ...  -3.5720e-02  2.9590e-02  9.6059e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-8.9671e-02 -1.4640e-01 -7.6023e-02  ...   5.3618e-02  4.2188e-02 -5.7987e-02\n",
      " 1.1660e-01 -1.5339e-01 -1.7843e-01  ...  -6.8916e-02  2.1696e-01  1.4607e-01\n",
      "-4.1288e-02  6.8910e-02  5.8062e-02  ...  -6.4028e-02 -1.7028e-01 -9.4468e-02\n",
      "[torch.FloatTensor of size 4600x1150]\n",
      "), ('0.rnns.1.module.bias_ih_l0', \n",
      "-0.8577\n",
      "-0.6784\n",
      "-0.7249\n",
      "   ⋮   \n",
      "-0.6782\n",
      " 0.0567\n",
      "-0.5026\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.1.module.bias_hh_l0', \n",
      "-0.8577\n",
      "-0.6784\n",
      "-0.7249\n",
      "   ⋮   \n",
      "-0.6782\n",
      " 0.0567\n",
      "-0.5026\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.1.module.weight_hh_l0_raw', \n",
      "-2.7305e-02 -2.2773e-01  7.8205e-02  ...   1.3548e-01 -1.2822e-01  1.6686e-01\n",
      " 1.2180e-01  1.6703e-03 -9.9806e-02  ...  -2.0854e-01 -6.8582e-02 -1.3887e-01\n",
      "-3.8784e-01 -4.9834e-02 -1.7484e-01  ...  -4.0139e-01  1.9860e-01 -4.4002e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-2.0972e-01 -4.2982e-01  3.5514e-01  ...   3.1637e-02 -1.1981e-01  1.2664e-01\n",
      " 3.7252e-03 -2.2282e-02  3.1754e-03  ...  -2.6722e-01 -3.0926e-01 -3.6104e-02\n",
      "-4.6356e-02  1.6639e-01 -1.3476e-01  ...   1.6005e-01 -1.1384e-01  8.4547e-02\n",
      "[torch.FloatTensor of size 4600x1150]\n",
      "), ('0.rnns.2.module.weight_ih_l0', \n",
      "-7.4091e-02  4.4678e-02 -7.4389e-02  ...  -4.1946e-02  1.5998e-01 -5.5267e-02\n",
      " 2.6980e-02  1.1813e-02  4.4894e-02  ...   1.1648e-01 -1.0802e-01 -6.8053e-02\n",
      "-1.0232e-01 -1.6619e-01 -2.2867e-02  ...   1.6523e-01 -1.0696e-01  9.6976e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-9.8934e-02 -4.4246e-01 -3.4288e-02  ...  -1.4339e-01  5.8510e-01 -2.9106e-02\n",
      " 8.0247e-02 -1.0668e-01  2.7895e-01  ...  -9.1596e-02 -2.2399e-01  1.0198e-01\n",
      "-4.0775e-01  7.2197e-01  1.1417e-01  ...   5.2866e-01  2.0347e-01 -1.8112e-01\n",
      "[torch.FloatTensor of size 1600x1150]\n",
      "), ('0.rnns.2.module.bias_ih_l0', \n",
      "-3.6805e-01\n",
      "-9.0794e-01\n",
      "-1.9982e-01\n",
      "     ⋮     \n",
      " 8.5325e-01\n",
      " 3.2018e-01\n",
      " 1.2172e+00\n",
      "[torch.FloatTensor of size 1600]\n",
      "), ('0.rnns.2.module.bias_hh_l0', \n",
      "-3.6805e-01\n",
      "-9.0792e-01\n",
      "-1.9983e-01\n",
      "     ⋮     \n",
      " 8.5325e-01\n",
      " 3.2018e-01\n",
      " 1.2172e+00\n",
      "[torch.FloatTensor of size 1600]\n",
      "), ('0.rnns.2.module.weight_hh_l0_raw', \n",
      "-9.6611e-02  2.3588e-02 -1.5181e-02  ...   3.8787e-02 -5.3053e-02 -3.9452e-02\n",
      "-3.2793e-02 -2.2166e-01  2.8448e-03  ...   1.4332e-02 -3.6839e-02 -8.4808e-03\n",
      " 1.6733e-02 -8.0697e-03 -5.6141e-02  ...   1.2456e-02  4.4213e-02 -1.3931e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-2.1206e-02 -1.0345e-01 -1.0618e-02  ...  -5.6113e-02  1.9981e-02 -1.5685e-02\n",
      " 1.8295e-02  3.6436e-02 -2.5082e-02  ...  -2.3954e-02 -1.1496e-01  4.5665e-03\n",
      " 9.9655e-03 -1.8239e-01  1.0762e-01  ...  -2.6931e-02  2.7332e-01  1.8456e-01\n",
      "[torch.FloatTensor of size 1600x400]\n",
      "), ('1.decoder.weight', \n",
      "-1.5972e-01  3.2485e-01 -4.4057e-01  ...  -1.4884e-01 -4.2950e-03  1.4028e-01\n",
      " 3.7763e-02 -3.9745e-02  5.0021e-02  ...   3.9405e-02  4.0394e-02 -2.1133e-02\n",
      "-3.8825e-01 -4.0622e-01 -1.7479e-01  ...   7.0953e-02  2.7808e-01  7.5862e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.2570e-02 -1.4090e-01  1.2269e-02  ...   1.2281e-02  5.5557e-02 -4.0179e-03\n",
      "-7.3162e-01 -1.1589e+00  3.6999e-01  ...   2.3351e-01 -6.6950e-02  4.2597e-02\n",
      "-3.1653e-01 -9.5473e-01 -1.0659e-01  ...  -2.2530e-01  2.1217e-01  2.5796e-01\n",
      "[torch.FloatTensor of size 4409x400]\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "lm_wgts_fr = torch.load('models/lm_last_ft.h5', map_location=lambda storage, \n",
    "                  loc: storage)\n",
    "print(lm_wgts_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreeze, lr_find Algorithmus\n",
    "\n",
    "Jetzt unfreeze, dann Erklärung lr_find Algorithmus\n",
    "\n",
    "<b>Was wichtig ist:</b> Um den Plot hier durch den Code hineinzuladen, müssen wir das Ding durchlaufen lassen. Das Bild hier per Bilddatei reinzuladen würde glaub am Ziel vorbeischrammen, das man das Notebook selbst nachbilden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load('lm_last_ft')\n",
    "#learner.unfreeze()\n",
    "#learner.lr_find(start_lr=lrs/1000, end_lr=lrs*1000)\n",
    "#learner.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zweiter Fit mit unfrozen Layers\n",
    "\n",
    "Dann erneuter Fit, hier muss noch die Learning neu gesetzt werden und evtl. mit discriminative learning rate angesetzt werden, da wir hier ja auch die LSTM Layer trainieren.\n",
    "\n",
    "Evtl. dann learner.save für die LM Prediction, kann aber auch raus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=4)\n",
    "#learner.save('lm2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfrozen Matrizen zeigen\n",
    "\n",
    "Erklärung zu den unfrozen Parametern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.encoder.weight', \n",
      "-1.4777e-01  3.5498e-01 -4.9052e-01  ...  -1.5741e-01 -3.6893e-02  7.1525e-02\n",
      " 9.0088e-02 -1.1824e-01  1.5968e-01  ...   1.5601e-01  1.3824e-01  1.0296e-02\n",
      "-3.7896e-01 -3.7842e-01 -1.9198e-01  ...   4.1058e-02  2.4902e-01  9.4805e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-2.0592e-02 -2.0642e-01  1.3304e-01  ...   9.0279e-02  9.7593e-02  2.9149e-02\n",
      "-6.7843e-01 -1.1849e+00  3.6680e-01  ...   3.5038e-01 -3.7000e-02  3.6783e-02\n",
      "-3.2418e-01 -1.0141e+00 -9.3502e-02  ...  -1.7836e-01  2.3915e-01  2.2841e-01\n",
      "[torch.FloatTensor of size 4409x400]\n",
      "), ('0.encoder_with_dropout.embed.weight', \n",
      "-1.4777e-01  3.5498e-01 -4.9052e-01  ...  -1.5741e-01 -3.6893e-02  7.1525e-02\n",
      " 9.0088e-02 -1.1824e-01  1.5968e-01  ...   1.5601e-01  1.3824e-01  1.0296e-02\n",
      "-3.7896e-01 -3.7842e-01 -1.9198e-01  ...   4.1058e-02  2.4902e-01  9.4805e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-2.0592e-02 -2.0642e-01  1.3304e-01  ...   9.0279e-02  9.7593e-02  2.9149e-02\n",
      "-6.7843e-01 -1.1849e+00  3.6680e-01  ...   3.5038e-01 -3.7000e-02  3.6783e-02\n",
      "-3.2418e-01 -1.0141e+00 -9.3502e-02  ...  -1.7836e-01  2.3915e-01  2.2841e-01\n",
      "[torch.FloatTensor of size 4409x400]\n",
      "), ('0.rnns.0.module.weight_ih_l0', \n",
      "-1.0283e-01 -4.2323e-02 -1.4958e-01  ...  -2.1195e-02 -1.2806e-01 -3.5614e-01\n",
      " 2.0536e-01  1.4978e-01  8.0277e-02  ...  -1.0815e-01  1.3758e-01 -5.8997e-02\n",
      "-2.7420e-02  1.3115e-01  2.4830e-01  ...  -1.0724e-01 -4.4745e-02 -7.6611e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 1.5614e-02  1.8628e-02  3.5444e-01  ...   1.3496e-01  1.0772e-01 -4.6958e-01\n",
      "-2.9506e-02  4.7927e-02  1.1606e-01  ...   3.4061e-01  4.3997e-03 -2.7983e-02\n",
      "-1.4079e-02 -1.5045e-01  2.3318e-01  ...   3.4364e-02 -2.8339e-02  1.5818e-01\n",
      "[torch.FloatTensor of size 4600x400]\n",
      "), ('0.rnns.0.module.bias_ih_l0', \n",
      " 1.4933e-01\n",
      "-4.7117e-01\n",
      "-2.0151e-01\n",
      "     ⋮     \n",
      "-6.1869e-01\n",
      "-2.0469e-01\n",
      "-1.0457e-01\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.0.module.bias_hh_l0', \n",
      " 1.4933e-01\n",
      "-4.7117e-01\n",
      "-2.0151e-01\n",
      "     ⋮     \n",
      "-6.1869e-01\n",
      "-2.0469e-01\n",
      "-1.0457e-01\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.0.module.weight_hh_l0_raw', \n",
      "-5.9682e-02  1.3191e-01 -5.9467e-02  ...   8.6010e-02  4.2332e-02  2.3331e-01\n",
      " 1.2823e-01 -8.3179e-02 -5.4943e-02  ...  -8.3033e-02 -1.4329e-01 -1.5371e-01\n",
      " 6.9691e-02 -3.4017e-02  8.6424e-02  ...   1.8858e-01  3.8339e-02 -1.7352e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-3.4832e-02 -4.6847e-02  1.5626e-01  ...   1.9783e-01 -4.0551e-02 -9.7501e-04\n",
      "-1.6380e-01 -3.0712e-02  1.4634e-01  ...  -4.2233e-02  5.5041e-01  2.5068e-02\n",
      " 1.1422e-01 -1.6535e-01 -1.2365e-03  ...  -2.8657e-03  2.3025e-01  3.7163e-02\n",
      "[torch.FloatTensor of size 4600x1150]\n",
      "), ('0.rnns.1.module.weight_ih_l0', \n",
      " 3.5105e-01  2.6048e-02  7.6011e-02  ...   1.0044e-01 -1.5436e-02  7.6141e-03\n",
      " 5.3081e-02  1.9156e-01  5.1563e-02  ...   6.8787e-02  4.2065e-02  1.9878e-01\n",
      "-2.0070e-01 -1.3958e-01  2.0447e-01  ...  -4.0582e-02  7.7331e-02  3.3390e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.0597e-01 -2.0465e-01 -4.1492e-02  ...   6.8677e-02  7.6964e-02 -4.8706e-02\n",
      " 1.2622e-01 -7.6322e-02 -1.2613e-01  ...  -3.7516e-02  2.6507e-01  9.9838e-02\n",
      "-3.7010e-02  8.1100e-02  7.6477e-02  ...  -9.2020e-02 -1.5602e-01 -1.0318e-01\n",
      "[torch.FloatTensor of size 4600x1150]\n",
      "), ('0.rnns.1.module.bias_ih_l0', \n",
      "-8.6302e-01\n",
      "-6.7598e-01\n",
      "-7.1451e-01\n",
      "     ⋮     \n",
      "-6.8787e-01\n",
      " 6.7198e-02\n",
      "-5.2076e-01\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.1.module.bias_hh_l0', \n",
      "-8.6302e-01\n",
      "-6.7598e-01\n",
      "-7.1451e-01\n",
      "     ⋮     \n",
      "-6.8787e-01\n",
      " 6.7198e-02\n",
      "-5.2076e-01\n",
      "[torch.FloatTensor of size 4600]\n",
      "), ('0.rnns.1.module.weight_hh_l0_raw', \n",
      " 2.6638e-02 -2.1540e-01  1.0391e-01  ...   1.7365e-01 -1.4374e-01  2.0273e-01\n",
      " 1.5810e-01  1.2215e-02 -8.8412e-02  ...  -2.6837e-01 -1.9556e-02 -1.4256e-01\n",
      "-3.3038e-01 -6.5173e-02 -9.7477e-02  ...  -4.4688e-01  1.6661e-01 -4.7865e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-2.2184e-01 -4.5600e-01  3.3178e-01  ...   1.4021e-02 -1.4397e-01  1.5410e-01\n",
      " 8.3172e-02 -3.7950e-03  4.6661e-02  ...  -2.2311e-01 -3.0209e-01 -5.3142e-02\n",
      "-7.7864e-02  1.7466e-01 -9.1508e-02  ...   1.4595e-01 -8.8679e-02  9.3831e-02\n",
      "[torch.FloatTensor of size 4600x1150]\n",
      "), ('0.rnns.2.module.weight_ih_l0', \n",
      "-1.0312e-01  2.9505e-02 -8.8237e-02  ...  -4.8399e-02  1.4528e-01 -5.7633e-02\n",
      " 6.3846e-03 -3.7725e-02  8.6508e-02  ...   6.8890e-02 -1.3978e-01 -6.8120e-02\n",
      "-7.5140e-02 -8.0479e-02  7.3242e-03  ...   1.5106e-01 -1.3915e-01  9.5971e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.3063e-01 -4.3085e-01 -8.3826e-02  ...  -1.2670e-01  5.2052e-01 -3.8076e-02\n",
      " 8.9475e-02 -1.3590e-01  2.1974e-01  ...  -1.1177e-01 -2.0395e-01  9.4676e-02\n",
      "-4.2045e-01  7.2344e-01  7.9193e-02  ...   5.2917e-01  1.9227e-01 -2.0461e-01\n",
      "[torch.FloatTensor of size 1600x1150]\n",
      "), ('0.rnns.2.module.bias_ih_l0', \n",
      "-3.6700e-01\n",
      "-9.1475e-01\n",
      "-1.8356e-01\n",
      "     ⋮     \n",
      " 8.9664e-01\n",
      " 3.2216e-01\n",
      " 1.2410e+00\n",
      "[torch.FloatTensor of size 1600]\n",
      "), ('0.rnns.2.module.bias_hh_l0', \n",
      "-3.6700e-01\n",
      "-9.1473e-01\n",
      "-1.8357e-01\n",
      "     ⋮     \n",
      " 8.9664e-01\n",
      " 3.2216e-01\n",
      " 1.2410e+00\n",
      "[torch.FloatTensor of size 1600]\n",
      "), ('0.rnns.2.module.weight_hh_l0_raw', \n",
      "-5.1015e-02  2.3641e-02 -1.7850e-02  ...   3.7078e-02 -5.0045e-02 -5.4643e-02\n",
      "-6.5243e-02 -2.4275e-01 -1.8589e-03  ...   2.8829e-02  1.5393e-02  9.4012e-03\n",
      " 2.2825e-02 -7.0849e-03 -5.3855e-02  ...   1.8561e-02  3.4253e-02 -6.7196e-03\n",
      "                ...                   ⋱                   ...                \n",
      "-5.6419e-02 -7.7704e-02 -3.8202e-02  ...  -9.2222e-02 -1.4034e-02 -2.9057e-02\n",
      "-1.4321e-02  1.9967e-02 -3.2870e-02  ...  -2.7580e-03 -1.1504e-01 -7.1738e-03\n",
      " 3.9613e-02 -1.5755e-01  6.8757e-02  ...  -1.5508e-02  2.4678e-01  2.1850e-01\n",
      "[torch.FloatTensor of size 1600x400]\n",
      "), ('1.decoder.weight', \n",
      "-1.4777e-01  3.5498e-01 -4.9052e-01  ...  -1.5741e-01 -3.6893e-02  7.1525e-02\n",
      " 9.0088e-02 -1.1824e-01  1.5968e-01  ...   1.5601e-01  1.3824e-01  1.0296e-02\n",
      "-3.7896e-01 -3.7842e-01 -1.9198e-01  ...   4.1058e-02  2.4902e-01  9.4805e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-2.0592e-02 -2.0642e-01  1.3304e-01  ...   9.0279e-02  9.7593e-02  2.9149e-02\n",
      "-6.7843e-01 -1.1849e+00  3.6680e-01  ...   3.5038e-01 -3.7000e-02  3.6783e-02\n",
      "-3.2418e-01 -1.0141e+00 -9.3502e-02  ...  -1.7836e-01  2.3915e-01  2.2841e-01\n",
      "[torch.FloatTensor of size 4409x400]\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "lm_wgts_unfr = torch.load('models/lm2.h5', map_location=lambda storage, \n",
    "                  loc: storage)\n",
    "print(lm_wgts_unfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save_encoder\n",
    "\n",
    "Jetzt Erklärung des save_encoder Befehls mit dem Abriss des Softmax Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.save_encoder('lm2_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Classifier Modell\n",
    "\n",
    "Einleitung Classifer, Struktur (aufsetzen der Linear Blocks auf den Encoder), Bild mit Classifierumrandung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter\n",
    "\n",
    "Parameter neu setzen, neue Parameter erklären, etc. Frage ist, ob wir das mit den min_lbl usw. einfach rausnehmen und einfach = 3 setzen, den vollen Code haben wir dann ja eh im preparation_code file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48\n",
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensätze mit Labels laden\n",
    "\n",
    "Nun laden wir die Daten aus dem clas Path, damit wir die Labels dazuhaben.\n",
    "\n",
    "Stoi und Itos brauchen wir nicht neu laden wie im Colab, haben das schon im Notebook drin.\n",
    "\n",
    "Hier wieder die Frage, welche wir von den Daten wir wirklich brauchen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load('clas/tmp/tok_trn.npy')\n",
    "tok_val = np.load('clas/tmp/tok_val.npy')\n",
    "\n",
    "trn_clas = np.load('clas/tmp/trn_ids.npy')\n",
    "val_clas = np.load('clas/tmp/val_ids.npy')\n",
    "trn_labels = np.load('clas/tmp/trn_labels.npy')\n",
    "val_labels = np.load('clas/tmp/val_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sortish Sampler\n",
    "\n",
    "Jetzt kommt die große Frage, ob und inwiefern wir den Sortish Sampler hineinnehmen. Er ist halt leider wichtig damit der Code funktioniert. Vielleicht können wir es aber auch so machen das wir im Preparation Code trn_dl und val_dl abspeichern und hier einfach über pickle oder np.load hineinladen und kurz skizzieren das für Datensätze sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), \n",
    "                          bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1,\n",
    "                    pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, \n",
    "                    pad_idx=1, sampler=val_samp)\n",
    "md = ModelData('', trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drops und RNN Classifier\n",
    "\n",
    "Erklärung \n",
    "\n",
    "Erklärung Drops Werte (scheint zu funktionieren, Howard hat selbst herumprobiert und die Kombination gefunden, gibt keinen Algorithmen um alle Drops gleichzeitig optimal zu bestimmen)\n",
    "\n",
    "Erklärung get_rnn_classifer\n",
    "\n",
    "<b> Erklärung Concat Pooling:</b> Würde hier mit dem Concat Pooling starten, mit dem Bild vielleicht dazu, da wir hier die $em\\_sz*3$ schon drin haben.\n",
    "\n",
    "Erläuterung Aufbau auf LSTMs (Concat Layer, Linear ReLU Layer 50, Classifier Softmax Layer 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])\n",
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.7\n",
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, \n",
    "                      n_layers=nl, pad_token=1,\n",
    "                      layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "                      dropouti=dps[0], wdrop=dps[1],        \n",
    "                      dropoute=dps[2], dropouth=dps[3])\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Learner\n",
    "\n",
    "Erklärung RNN_Learner, dazu reg_fn und clip Attribute. Kurz Accuracy abhandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative Learning Rates\n",
    "\n",
    "Erläuterung DLRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay und Encoder\n",
    "\n",
    "WD könnten wir eigentlich auch zu den anderen Parametern packen. \n",
    "\n",
    "Jetzt Referenz zum Encoder, wir bauen die gespeicherten Embeddings und LSTMs vor unseren RNN Classifier um das Transfer Learning zu ermöglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "learn.load_encoder('lm2_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradual unfreezing\n",
    "\n",
    "Wieder unfreezing, dieses Mal Gradual Unfreezing mit mehreren Stufen, da wir nach dem LSTM nun zwei untrainierte Layer im Classifier (nicht wie im LM ein Softmax Layer) haben und diese nacheinander antrainieren. Denke hier müssen die Matrizen dann nicht mehr gezeigt werden. Ich kann ja zur Not die zwei Codezeilen dazu in Kommentare packen.\n",
    "\n",
    "Dazu dann wieder Referenz zum LR_find, danach der Plot (Modell muss im JN durchlaufen). Für den Fit mit DLR $lrs$.\n",
    "\n",
    "Den learn.save brauchen wir eigentlich nur, falls ich die Weightmatrizen zwecks Unfreezing nochmal zeigen soll\n",
    "\n",
    "(Ignoriert den Plot, hab am Anfang aus Versehen ohne Hashtag vorm lr_find durchlaufen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-1)\n",
    "#learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()\n",
    "#learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))\n",
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing Matrix 1\n",
    "\n",
    "Optional Matrizen für Freezing 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clas_wgts_fr1 = torch.load('models/clas_0.h5', map_location=lambda storage, \n",
    "#                 loc: storage)\n",
    "#print(clas_wgts_fr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zweiter Fit\n",
    "\n",
    "Gradual Unfreezing des ReLU 50 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing Matrix 2\n",
    "\n",
    "Optional Matrizen für Freezing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clas_wgts_fr2 = torch.load('models/clas_1.h5', map_location=lambda storage, \n",
    "#                 loc: storage)\n",
    "#print(clas_wgts_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finaler Fit\n",
    "\n",
    "Unfreeze aller Layer (muss wieder durchlaufen um Losses und Accuracy zu zeigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=5, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Matrix final\n",
    "\n",
    "Optional Matrizen für Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clas_wgts_unfr = torch.load('models/clas_2.h5', map_location=lambda storage, \n",
    "#                 loc: storage)\n",
    "#print(clas_wgts_unfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Wie läuft Input durchs Model durch das Model durch (Numpy Michi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Preparation\n",
    "\n",
    "Vorbereitender Code, muss hier aber hinein damit man selbst den Satz festlegen kann für das Modell falls wir eine Prediction machen wollen (was schon ganz cool wäre), vielleicht kann man den Code hier verstecken.\n",
    "\n",
    "Muss mir da noch eine elegantere Lösung überlegen wie ich das sauber hier hineinbekomme. Vermutlich werde ich das irgendwie mit Ausführung und Ablegung im Preparation_Code machen und das dann hier einfach hineinladen. Ich kann ja darauf verweisen dass man zum Ändern des Satzes im Preparation Code das neu laufen und abspeichern muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/Users/michaelschimpke/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "text = 'My flight was on'\n",
    "labels = 0\n",
    "text = pd.Series(text)\n",
    "labels = pd.Series(labels)\n",
    "\n",
    "text = pd.Series.as_matrix(text)\n",
    "labels = pd.Series.as_matrix(labels)\n",
    "\n",
    "colNames = ['labels','text']\n",
    "textdf = pd.DataFrame({'text':text, 'labels':labels}, columns = colNames)\n",
    "textdf.to_csv('Test_lm/text.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach dem aktuellen Stand brauch ich noch die get_all, versuche aber das rauszukriegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "# cleaning function\n",
    "def cleaning(x):\n",
    "   x = x.replace('#', '').replace('&amp;', '&')\n",
    "   #return re1.sub(' ', html.unescape(x))\n",
    "   return re1.sub(' ', re.sub('https?://[A-Za-z0-9./]+', '',html.unescape(x)))\n",
    "\n",
    "\n",
    "# tokenizer function\n",
    "def get_texts(df, n_lbls=1):\n",
    "    labels = np.unique(df.iloc[:,range(n_lbls)].values, return_inverse=True)[n_lbls]\n",
    "    texts = f'\\n{BOS} ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): \n",
    "        texts += df[i].astype(str)\n",
    "    texts = texts.apply(cleaning).values.astype(str)\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)\n",
    "\n",
    "# iterator function\n",
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-d17c63185f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtextdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test_lm/text.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtok_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtok_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-25d72ceb3d4b>\u001b[0m in \u001b[0;36mget_all\u001b[0;34m(df, n_lbls)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtok_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtok\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtok_\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-25d72ceb3d4b>\u001b[0m in \u001b[0;36mget_texts\u001b[0;34m(df, n_lbls)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc_all_mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_by_cores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/fastai/text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre_br\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<\\s*br\\s*/?>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<bos>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<unk>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mORTH\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "chunksize = 1\n",
    "BOS = 'xbos'\n",
    "textdf = pd.read_csv('Test_lm/text.csv', header=None, chunksize=chunksize)\n",
    "\n",
    "tok_text = get_all(textdf,1)\n",
    "tok = (tok_text[0])\n",
    "print(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel erste Wörter aus Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_unk_', 0),\n",
       " ('_pad_', 1),\n",
       " ('\\n', 2),\n",
       " ('xbos', 3),\n",
       " ('.', 4),\n",
       " ('to', 5),\n",
       " ('i', 6),\n",
       " ('the', 7),\n",
       " ('t_up', 8),\n",
       " ('!', 9)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stoi.items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenized Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-c495da0ca742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Numeral tokens for words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextLm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtextLm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextLm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextLm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tok' is not defined"
     ]
    }
   ],
   "source": [
    "#Numeral tokens for words\n",
    "textLm = [[stoi[o] for o in p] for p in tok]\n",
    "textLm = textLm[0]\n",
    "print(textLm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
